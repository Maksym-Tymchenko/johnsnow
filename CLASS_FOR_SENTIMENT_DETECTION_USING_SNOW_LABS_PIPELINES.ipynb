{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maksym-Tymchenko/johnsnow/blob/main/CLASS_FOR_SENTIMENT_DETECTION_USING_SNOW_LABS_PIPELINES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oYgZXG4gDt1"
      },
      "source": [
        "# **Class for Sentiment Analysis for News Articles**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c9xk47mgkcB"
      },
      "source": [
        "## Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDySD2IHU9di"
      },
      "outputs": [],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.1.2 spark-nlp\n",
        "\n",
        "# Install Spark NLP Display lib\n",
        "! pip install --upgrade -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnOW8Mt7VH97",
        "outputId": "44100a76-b335-4d97-f620-6449adb6270b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  3.4.1\n",
            "Apache Spark version:  3.1.2\n"
          ]
        }
      ],
      "source": [
        "import sparknlp\n",
        "import pandas as pd\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from tabulate import tabulate\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a News Article"
      ],
      "metadata": {
        "id": "BDijGosdPGzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article = [ # two strings - headline & article body\n",
        "\"\"\"Google sued in US over 'deceptive' location tracking\"\"\", # headline\n",
        "\"\"\"Google is being sued in the US over accusations it deceived people about how to control location tracking.\n",
        "\n",
        "The legal action refers to a widely reported 2018 revelation turning off one location-tracking setting in its apps was insufficient to fully disable the feature.\n",
        "\n",
        "It accuses Google of using so-called dark patterns, marketing techniques that deliberately confuse.\n",
        "\n",
        "Google said the claims were inaccurate and outdated.\n",
        "\n",
        "'Unfair practices'\n",
        "The legal action was filed in the District of Columbia. Similar ones were also filed in Texas, Indiana and Washington state.\n",
        "\n",
        "It refers to an Associated Press revelation turning off Location History when using Google Maps or Search was insufficient - as a separate setting, Web and App Activity, continued to log location and other personal data.\n",
        "\n",
        "The study, with researchers at Princeton University, found up to two billion Android and Apple devices could be affected.\n",
        "\n",
        "\"Google has relied on, and continues to rely on, deceptive and unfair practices that make it difficult for users to decline location tracking or to evaluate the data collection and processing to which they are purportedly consenting,\" the legal action alleges.\n",
        "\n",
        "'Robust controls'\n",
        "Google told BBC News the case was based \"on inaccurate claims and outdated assertions about our settings\".\n",
        "\n",
        "A representative added: \"We have always built privacy features into our products and provided robust controls for location data.\n",
        "\n",
        "\"We will vigorously defend ourselves and set the record straight.\"\n",
        "\n",
        "Visual misdirection\n",
        "The legal action claims Google's policies contained other \"misleading, ambiguous and incomplete descriptions... but guarantee that consumers will not understand when their location is collected and retained by Google or for what purposes\".\n",
        "\n",
        "It refers to dark patterns, design choices that alter users' decision-making for the designer's benefit - such as, complicated navigation menus, visual misdirection, confusing wording and repeated nudging towards a particular outcome.\n",
        "\n",
        "Data regulators are increasingly focusing on these practices.\n",
        "\n",
        "Google faces a raft of other legal actions in the US, including:\n",
        "\n",
        "In May 2020, Arizona filed a legal action over the same issue\n",
        "In December 2020, multiple US states sued over the price and process of advertising auctions\n",
        "In October 2020, the US Justice Department alleged Google had a monopoly over search and search advertising\"\"\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "kzD5yHCBTfKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Brand Identification Class"
      ],
      "metadata": {
        "id": "rmq_-RXkbB1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BrandIdentification:\n",
        "    def __init__(self, MODEL_NAME):\n",
        "        self.MODEL_NAME = MODEL_NAME\n",
        "\n",
        "        # Define Spark NLP pipeline \n",
        "        documentAssembler = DocumentAssembler() \\\n",
        "            .setInputCol('text') \\\n",
        "            .setOutputCol('document')\n",
        "\n",
        "        tokenizer = Tokenizer() \\\n",
        "            .setInputCols(['document']) \\\n",
        "            .setOutputCol('token')\n",
        "\n",
        "        # ner_dl and onto_100 model are trained with glove_100d, so the embeddings in the pipeline should match\n",
        "        if (self.MODEL_NAME == \"ner_dl\") or (self.MODEL_NAME == \"onto_100\"):\n",
        "            embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\n",
        "                .setInputCols([\"document\", 'token']) \\\n",
        "                .setOutputCol(\"embeddings\")\n",
        "\n",
        "        # Bert model uses Bert embeddings\n",
        "        elif self.MODEL_NAME == \"ner_dl_bert\":\n",
        "            embeddings = BertEmbeddings.pretrained(name='bert_base_cased', lang='en') \\\n",
        "                .setInputCols(['document', 'token']) \\\n",
        "                .setOutputCol('embeddings')\n",
        "\n",
        "        ner_model = NerDLModel.pretrained(MODEL_NAME, 'en') \\\n",
        "            .setInputCols(['document', 'token', 'embeddings']) \\\n",
        "            .setOutputCol('ner')\n",
        "\n",
        "        ner_converter = NerConverter() \\\n",
        "            .setInputCols(['document', 'token', 'ner']) \\\n",
        "            .setOutputCol('ner_chunk')\n",
        "\n",
        "        nlp_pipeline = Pipeline(stages=[\n",
        "            documentAssembler, \n",
        "            tokenizer,\n",
        "            embeddings,\n",
        "            ner_model,\n",
        "            ner_converter\n",
        "        ])\n",
        "        \n",
        "        # Create the pipeline model\n",
        "        empty_df = spark.createDataFrame([['']]).toDF('text')\n",
        "        self.pipeline_model = nlp_pipeline.fit(empty_df)\n",
        "\n",
        "\n",
        "    def create_ranked_result_df(self, text):\n",
        "        # Run the pipeline for the text\n",
        "        text_df = spark.createDataFrame(pd.DataFrame({'text': text}, index = [0]))\n",
        "        result = self.pipeline_model.transform(text_df)\n",
        "        \n",
        "        # Tabulate results\n",
        "        df = result.select(F.explode(F.arrays_zip('document.result', 'ner_chunk.result',\"ner_chunk.metadata\")).alias(\"cols\")).select(\\\n",
        "        F.expr(\"cols['1']\").alias(\"chunk\"),\n",
        "        F.expr(\"cols['2'].entity\").alias('result'))\n",
        "        \n",
        "        # Rank the identified ORGs by frequencies\n",
        "        ranked_df = df.filter(df.result == 'ORG').groupBy(df.chunk).count().orderBy('count', ascending=False)\n",
        "\n",
        "        return ranked_df\n",
        "\n",
        "\n",
        "    def predict_by_headline(self, headline):\n",
        "        ranked_df_hl = self.create_ranked_result_df(headline)\n",
        "        ranked_df_hl.show(100, truncate=False)\n",
        "\n",
        "        # If only one ORG appears in headline, return it \n",
        "        if ranked_df_hl.count() == 1:\n",
        "            return ranked_df_hl.first()[0] \n",
        "        else: # If no ORG appears, or multiple ORGs all appear once, return no brand\n",
        "            return None\n",
        "\n",
        "\n",
        "    def predict(self, body):\n",
        "        ranked_df = self.create_ranked_result_df(body)\n",
        "        ranked_df.show(100, truncate=False)\n",
        "\n",
        "        # Return the ORG with highest freq (at least greater than 2)\n",
        "        if ranked_df.first()[1] > 2: \n",
        "            return ranked_df.first()[0] \n",
        "        else:\n",
        "            return None\n",
        "        # TO DO: break even - Wikidata#\n",
        "\n",
        "\n",
        "    # def visualise(self, ranked_df, result):\n",
        "        # Visualise ORG names in text\n",
        "        # NerVisualizer().display(\n",
        "            # result = result.collect()[0],\n",
        "            # label_col = 'ner_chunk',\n",
        "            # document_col = 'document',\n",
        "            # labels=['ORG']\n",
        "        #)\n"
      ],
      "metadata": {
        "id": "5JQeWnV1a8Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Senitment Identification Class"
      ],
      "metadata": {
        "id": "-5m65UosNdY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentIdentification:\n",
        "\n",
        "    def __init__(self, MODEL_NAME):\n",
        "        \"\"\"Creates a class for sentiment identication using specified model.\n",
        "\n",
        "        Args:\n",
        "          MODEL_NAME: Name of the Spark NLP pretrained pipeline.\n",
        "        \"\"\"\n",
        "\n",
        "        # Create the pipeline instance\n",
        "        self.MODEL_NAME = MODEL_NAME\n",
        "\n",
        "        if self.MODEL_NAME == \"custom_pipeline\": # https://nlp.johnsnowlabs.com/2021/11/03/bert_sequence_classifier_finbert_en.html\n",
        "          document_assembler = DocumentAssembler() \\\n",
        "              .setInputCol('text') \\\n",
        "              .setOutputCol('document')\n",
        "\n",
        "          tokenizer = Tokenizer() \\\n",
        "              .setInputCols(['document']) \\\n",
        "              .setOutputCol('token')\n",
        "\n",
        "          sequenceClassifier = BertForSequenceClassification \\\n",
        "                .pretrained('bert_sequence_classifier_finbert', 'en') \\\n",
        "                .setInputCols(['token', 'document']) \\\n",
        "                .setOutputCol('class') \\\n",
        "                .setCaseSensitive(True) \\\n",
        "                .setMaxSentenceLength(512)\n",
        "\n",
        "          pipeline = Pipeline(stages=[\n",
        "              document_assembler,\n",
        "              tokenizer,\n",
        "              sequenceClassifier\n",
        "          ])\n",
        "\n",
        "          self.pipeline_model = LightPipeline(pipeline.fit(spark.createDataFrame([['']]).toDF(\"text\")))\n",
        "\n",
        "        else:\n",
        "          self.pipeline_model = PretrainedPipeline(self.MODEL_NAME, lang = 'en')\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, text):\n",
        "        \"\"\"Predicts sentiment of the input string..\n",
        "\n",
        "        Args:\n",
        "          text: String to classify.\n",
        "        \"\"\"\n",
        "        self.text = text\n",
        "\n",
        "        # Annotate input text using pretrained model\n",
        "        annotations =  self.pipeline_model.annotate(self.text)\n",
        "\n",
        "        # Depending on the chosen pipeline the outputs will be slightly different\n",
        "        if self.MODEL_NAME == \"analyze_sentimentdl_glove_imdb\":\n",
        "          # print(f\"{annotations['sentiment']} {annotations['document']}\")\n",
        "\n",
        "          if isinstance(self.text, list):\n",
        "            return [annotation['sentiment'][0] for annotation in annotations] # Return the sentiment list of strings\n",
        "          else:\n",
        "            return annotations['sentiment'][0] # Return the sentiment string\n",
        "\n",
        "        else:\n",
        "          # print(f\"{annotations['class']} {annotations['document']}\")\n",
        "\n",
        "          if isinstance(self.text, list):\n",
        "            return [annotation['class'][0] for annotation in annotations] # Return the sentiment list of strings\n",
        "          else:\n",
        "            return annotations['class'][0] # Return the sentiment string"
      ],
      "metadata": {
        "id": "62AefsLpNiTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify Brand in news article\n"
      ],
      "metadata": {
        "id": "MwBY37mRbKjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"ner_dl_bert\" # MODEL_NAME = \"onto_100\"\n",
        "\n",
        "brand_identifier = BrandIdentification(MODEL_NAME)\n",
        "headline, body = article\n",
        "\n",
        "headline_brand = brand_identifier.predict_by_headline(headline)\n",
        "print(headline)\n",
        "print(headline_brand)\n",
        "\n",
        "# Only use article body if no brand identified in the headline\n",
        "if headline_brand == None:\n",
        "    brand = brand_identifier.predict(body)\n",
        "    print(brand)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUgFEXqubJwk",
        "outputId": "45140620-d570-441d-fad7-16c627de389f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.1 MB\n",
            "[OK!]\n",
            "ner_dl_bert download started this may take some time.\n",
            "Approximate size to download 15.4 MB\n",
            "[OK!]\n",
            "+------+-----+\n",
            "|chunk |count|\n",
            "+------+-----+\n",
            "|Google|1    |\n",
            "+------+-----+\n",
            "\n",
            "Google sued in US over 'deceptive' location tracking\n",
            "Google\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify article using chosen pipeline"
      ],
      "metadata": {
        "id": "HoTrh-sEUeRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identifier = SentimentIdentification(MODEL_NAME =  \"analyze_sentimentdl_glove_imdb\")\n",
        "# identifier = SentimentIdentification(MODEL_NAME =  \"classifierdl_bertwiki_finance_sentiment_pipeline\")\n",
        "identifier = SentimentIdentification(MODEL_NAME = \"custom_pipeline\") # Uses https://nlp.johnsnowlabs.com/2021/11/03/bert_sequence_classifier_finbert_en.html\n",
        "\n",
        "# Predict by headline\n",
        "headline = article[0]\n",
        "identifier.predict(headline)\n",
        "\n",
        "# Predict by body\n",
        "body = article[1]\n",
        "identifier.predict(body)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "RMwzvEYnPKEQ",
        "outputId": "b99a513b-b77a-43d4-a35b-12daf557a813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_sequence_classifier_finbert download started this may take some time.\n",
            "Approximate size to download 390.9 MB\n",
            "[OK!]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'negative'"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the accuracy of sentiment using the Financial News Headline Dataset"
      ],
      "metadata": {
        "id": "5GVcdPcr3Ldk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data downloaded from here: https://www.kaggle.com/ankurzing/sentiment-analysis-for-financial-news/version/5\n",
        "# Upload data from local machine\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "metadata": {
        "id": "ICt2AFBB4VEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alternatively download directly from kaggle using api keys"
      ],
      "metadata": {
        "id": "r20tUnSUyhbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/ankurzing/sentiment-analysis-for-financial-news?select=all-data.csv\")\n",
        "\n",
        "# Input the following username and key when prompted:\n",
        "# username: maxtimm\n",
        "# Key: e9e0955b8d40b7d939e21febfbea8d15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdW7RAb1ygtU",
        "outputId": "ee405983-4d06-4f82-e401-6ead9b1b1dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.7/dist-packages (0.1.20)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.62.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2021.10.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (5.0.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Skipping, found downloaded files in \"./sentiment-analysis-for-financial-news\" (use force=True to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert Kaggle to dataframe and preprocess"
      ],
      "metadata": {
        "id": "LA3mYD2kK2V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import time\n",
        "\n",
        "# Store data in a Pandas Dataframe\n",
        "df_pandas = pd.read_csv(\"./sentiment-analysis-for-financial-news/all-data.csv\", encoding='latin-1')\n",
        "\n",
        "# Change column names (pipelines require a \"text\" column to predict)\n",
        "df_pandas.columns = ['True_Sentiment', 'text']\n",
        "\n",
        "# shuffle the DataFrame rows\n",
        "df_pandas = df_pandas.sample(frac = 1)\n",
        "\n",
        "# Make dataset smaller for faster runtime\n",
        "num_sentences = 10\n",
        "total_num_sentences = df_pandas.shape[0]\n",
        "df_pandas.drop(df_pandas.index[num_sentences:total_num_sentences], inplace=True)"
      ],
      "metadata": {
        "id": "nwLHDZohOPJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Â Classify sentences one by one"
      ],
      "metadata": {
        "id": "0jQZPrKIOP3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the identifier object\n",
        "# identifier = SentimentIdentification(MODEL_NAME = \"custom_pipeline\") # 90.2% accuracy on 500 sentences 89.8% on 1000 sentences\n",
        "# identifier = SentimentIdentification(MODEL_NAME =  \"classifierdl_bertwiki_finance_sentiment_pipeline\") # Alternative pretrained pipeline 90.0% accuracy on 500 sentences\n",
        "\n",
        "preds = []\n",
        "target = []\n",
        "ignored_idxs = []\n",
        "sentiment_to_ignore = \"\" # e.g. neutral\n",
        "\n",
        "# Measure how long it takes\n",
        "start = time.time()\n",
        "\n",
        "# Collect predicted sentiment for each headline - take three minutes to run\n",
        "for idx, hl in enumerate(df_pandas['text']):\n",
        "\n",
        "    # Only append the sentiment if it is not the sentiment to ignore (e.g. neutral)\n",
        "    target_sentiment = df_pandas[\"True_Sentiment\"][df_pandas.index[idx]]\n",
        "\n",
        "    if target_sentiment != sentiment_to_ignore:\n",
        "      preds.append(identifier.predict(hl))\n",
        "    else:\n",
        "      ignored_idxs.append(idx)\n",
        "\n",
        "    # Print progress\n",
        "    if idx % 25 == 0:\n",
        "      print(f\"Classification {100*idx/num_sentences}% done.\")\n",
        "\n",
        "# Remove all ignored entries from dataset\n",
        "df_pandas.drop(df_pandas.index[ignored_idxs], inplace=True)\n",
        "\n",
        "df_pandas['Predicted_Sentiment'] = preds\n",
        "\n",
        "# Measure how long it takes\n",
        "end = time.time()\n",
        "print(f\"{end-start} seconds elapsed to classify {num_sentences} sentences.\")\n",
        "\n",
        "# Modify predicted labels to match with true labels\n",
        "# df = df.replace({'Predicted Sentiment': {'pos' : 'positive', 'neg' : 'negative'}})\n",
        "\n",
        "df_pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "5jFhoWw54zMo",
        "outputId": "e5c948ad-62d0-406c-9bdb-f05c52f8b32e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification 0.0% done.\n",
            "2.318124771118164 seconds elapsed to classify 10 sentences.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-87665de4-357c-4199-94b5-fee104c955de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>True_Sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>Predicted_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2090</th>\n",
              "      <td>positive</td>\n",
              "      <td>Diluted loss per share stood at EUR 0.15 versu...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>positive</td>\n",
              "      <td>Operating profit totaled EUR 5.5 mn , up from ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1991</th>\n",
              "      <td>positive</td>\n",
              "      <td>Markets had been expecting a poor performance ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4685</th>\n",
              "      <td>negative</td>\n",
              "      <td>( ADP News ) - Feb 4 , 2009 - Finnish broadban...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2711</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Swedbank Hypotek - Is to issue a benchmark , f...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>825</th>\n",
              "      <td>positive</td>\n",
              "      <td>BasWare 's CEO Ilkka Sihvo comments in conjunc...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>positive</td>\n",
              "      <td>The stock rose for a third day on Tuesday brin...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1220</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Finnish consumers prefer to buy the cheapest b...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2036</th>\n",
              "      <td>neutral</td>\n",
              "      <td>The Board of Directors proposes to the Shareho...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>561</th>\n",
              "      <td>positive</td>\n",
              "      <td>Kazgiprotsvetmet and Outotec Finland have sign...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87665de4-357c-4199-94b5-fee104c955de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-87665de4-357c-4199-94b5-fee104c955de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-87665de4-357c-4199-94b5-fee104c955de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     True_Sentiment  ... Predicted_Sentiment\n",
              "2090       positive  ...            negative\n",
              "255        positive  ...            positive\n",
              "1991       positive  ...            positive\n",
              "4685       negative  ...            negative\n",
              "2711        neutral  ...             neutral\n",
              "825        positive  ...            positive\n",
              "300        positive  ...            positive\n",
              "1220        neutral  ...             neutral\n",
              "2036        neutral  ...             neutral\n",
              "561        positive  ...            positive\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Measure the Accuracy"
      ],
      "metadata": {
        "id": "OugF9Z-6t0PT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = df_pandas['True_Sentiment'].to_numpy()\n",
        "y_pred = df_pandas['Predicted_Sentiment'].to_numpy()\n",
        "\n",
        "print(f\"The accuracy is {100* sum(y_true==y_pred)/len(y_true)}%. \\n\")\n",
        "\n",
        "target_names = ['positive', 'neutral', 'negative']\n",
        "\n",
        "# Compute classification metrics - poor accuracy\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiLV0Glo_Kzj",
        "outputId": "f5753b08-47bf-4d42-9f2b-8e9afc55706e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 90.0%. \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.50      1.00      0.67         1\n",
            "     neutral       1.00      1.00      1.00         3\n",
            "    negative       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.90        10\n",
            "   macro avg       0.83      0.94      0.86        10\n",
            "weighted avg       0.95      0.90      0.91        10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classify using Spark Dataframe as input"
      ],
      "metadata": {
        "id": "PJc83LMsgJqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import array_join\n",
        "from pyspark.sql.functions import col, explode, expr, greatest\n",
        "\n",
        "# Define pretrained pipeline\n",
        "# pipeline = PretrainedPipeline(\"classifierdl_bertwiki_finance_sentiment_pipeline\", lang = 'en')\n",
        "\n",
        "# Convert to spark dataframe for faster prediction\n",
        "df_spark = spark.createDataFrame(df_pandas) \n",
        "\n",
        "# Measure how long it takes\n",
        "start = time.time()\n",
        "\n",
        "# Predict the sentiment\n",
        "df_spark = pipeline.transform(df_spark)\n",
        "\n",
        "# print(df_spark.first()['class'])\n",
        "# df_spark.printSchema()\n",
        "\n",
        "#Extract sentiment score\n",
        "df_spark_scores = df_spark.select(explode(col(\"class.metadata\")).alias(\"metadata\")).select(col(\"metadata\")[\"positive\"].alias(\"positive\"),\n",
        "                                                                                    col(\"metadata\")[\"neutral\"].alias(\"neutral\"),\n",
        "                                                                                    col(\"metadata\")[\"negative\"].alias(\"negative\"),)\n",
        "df_pandas_scores = df_spark_scores.toPandas()\n",
        "\n",
        "# df_spark_scores = df_spark_scores.withColumn('max_val', greatest('positive', 'negative', 'neutral')) # Doesn't work because of scientific notation\n",
        "\n",
        "# df_spark_scores.show()\n",
        "\n",
        "\n",
        "# Extract only targets and labels\n",
        "df_spark = df_spark.select(\"text\", \"True_Sentiment\", \"class.result\")\n",
        "\n",
        "# Rename to Predicted Sentiment\n",
        "df_spark = df_spark.withColumnRenamed(\"result\",\"Predicted_Sentiment\")\n",
        "\n",
        "# Convert sentiment from a list to a string\n",
        "df_spark = df_spark.withColumn(\"Predicted_Sentiment\", array_join(\"Predicted_Sentiment\", \"\"))\n",
        "\n",
        "# Convert to pandas dataframe for postprocessing (https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32)\n",
        "df_pandas = df_spark.toPandas()\n",
        "\n",
        "# df_pandas[\"Predicted_Sentiment\"] = df_pandas[\"Predicted_Sentiment\"].apply(lambda x: x[0]) # Alternative to convert list to string\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end-start} seconds elapsed to classify {num_sentences} sentences.\")\n",
        "\n",
        "df_pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "plG0dY_MZu5Z",
        "outputId": "807fbad6-75a8-4242-efde-13416ff03c64"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-99aa6f57f474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_join\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreatest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define pretrained pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# pipeline = PretrainedPipeline(\"classifierdl_bertwiki_finance_sentiment_pipeline\", lang = 'en')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute the Accuracy"
      ],
      "metadata": {
        "id": "jsCyAYiYOutA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Compute the accuracy\n",
        "accuracy = accuracy_score(df_pandas[\"True_Sentiment\"], df_pandas[\"Predicted_Sentiment\"])\n",
        "print(f\"The accuracy is {accuracy*100}%.\")\n",
        "print(classification_report(df_pandas[\"True_Sentiment\"], df_pandas[\"Predicted_Sentiment\"]))\n",
        "\n",
        "# # Alternatively if not converted to pandas dataframe, use the following for the accuracy\n",
        "# # Compute accuracy by comparing each true label with predicted label\n",
        "# start = time.time()\n",
        "# accuracy = df_spark.filter(df_spark.Predicted_Sentiment == df_spark.True_Sentiment).count()/ num_sentences\n",
        "# end = time.time()\n",
        "# print(f\"{end-start} seconds elapsed to calculate accuracy of {num_sentences} sentences.\")\n",
        "# print(f\"The accuracy is {accuracy*100}%.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZsstjzhOtko",
        "outputId": "574d8b3b-aa2d-4afe-c371-f65183599832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 90.0%.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     neutral       1.00      0.83      0.91         6\n",
            "    positive       0.80      1.00      0.89         4\n",
            "\n",
            "    accuracy                           0.90        10\n",
            "   macro avg       0.90      0.92      0.90        10\n",
            "weighted avg       0.92      0.90      0.90        10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alternatively extract predictions as strings (takes much longer)"
      ],
      "metadata": {
        "id": "bgCjIm4CK8mT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Extract the predictions from the dataframe\n",
        "# annotations_list = result.select(\"class.result\").collect()\n",
        "# sentiment_list = [annotations_list[i].result[0] for i in range(num_sentences)]\n",
        "\n",
        "# # Annotate previous dataframe for visualization\n",
        "# df_pandas['Predicted Sentiment'] = sentiment_list\n",
        "\n",
        "# # Move text column to the beginning\n",
        "# text_column = df_pandas.pop('text')\n",
        "# df_pandas.insert(0, 'Headline', text_column)\n",
        "\n",
        "# display(df_pandas)\n",
        "\n",
        "# y_true = df_pandas['True Sentiment'].to_numpy()\n",
        "# y_pred = df_pandas['Predicted Sentiment'].to_numpy()\n",
        "\n",
        "# print(f\"The accuracy is {100* sum(y_true==y_pred)/len(y_true)}%. \\n\")"
      ],
      "metadata": {
        "id": "FE7qhsf8LAre"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CLASS FOR SENTIMENT DETECTION USING SNOW LABS PIPELINES.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "45150093197569bb3a58481dcd32cd1adb45462fa3448719e8ac38ada6166aca"
    },
    "kernelspec": {
      "display_name": "Python 3.6.10 64-bit ('tensorflow2_p36': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}