{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maksym-Tymchenko/johnsnow/blob/main/CLASS_FOR_SENTIMENT_DETECTION_USING_SNOW_LABS_PIPELINES_better_speed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oYgZXG4gDt1"
      },
      "source": [
        "# **Class for Sentiment Analysis for News Articles**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c9xk47mgkcB"
      },
      "source": [
        "## Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pDySD2IHU9di",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d076805-41ab-4113-f32b-322ee38620c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 37 kB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 47.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 9.0 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 95 kB 2.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 66 kB 3.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.1.2 spark-nlp\n",
        "\n",
        "# Install Spark NLP Display lib\n",
        "! pip install --upgrade -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnOW8Mt7VH97",
        "outputId": "ae63eb2d-6337-4e6d-a916-bb158748efa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  3.4.1\n",
            "Apache Spark version:  3.1.2\n"
          ]
        }
      ],
      "source": [
        "import sparknlp\n",
        "import pandas as pd\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from tabulate import tabulate\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a News Article"
      ],
      "metadata": {
        "id": "BDijGosdPGzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article = [ # two strings - headline & article body\n",
        "\"\"\"Google sued in US over 'deceptive' location tracking\"\"\", # headline\n",
        "\"\"\"Google is being sued in the US over accusations it deceived people about how to control location tracking.\n",
        "\n",
        "The legal action refers to a widely reported 2018 revelation turning off one location-tracking setting in its apps was insufficient to fully disable the feature.\n",
        "\n",
        "It accuses Google of using so-called dark patterns, marketing techniques that deliberately confuse.\n",
        "\n",
        "Google said the claims were inaccurate and outdated.\n",
        "\n",
        "'Unfair practices'\n",
        "The legal action was filed in the District of Columbia. Similar ones were also filed in Texas, Indiana and Washington state.\n",
        "\n",
        "It refers to an Associated Press revelation turning off Location History when using Google Maps or Search was insufficient - as a separate setting, Web and App Activity, continued to log location and other personal data.\n",
        "\n",
        "The study, with researchers at Princeton University, found up to two billion Android and Apple devices could be affected.\n",
        "\n",
        "\"Google has relied on, and continues to rely on, deceptive and unfair practices that make it difficult for users to decline location tracking or to evaluate the data collection and processing to which they are purportedly consenting,\" the legal action alleges.\n",
        "\n",
        "'Robust controls'\n",
        "Google told BBC News the case was based \"on inaccurate claims and outdated assertions about our settings\".\n",
        "\n",
        "A representative added: \"We have always built privacy features into our products and provided robust controls for location data.\n",
        "\n",
        "\"We will vigorously defend ourselves and set the record straight.\"\n",
        "\n",
        "Visual misdirection\n",
        "The legal action claims Google's policies contained other \"misleading, ambiguous and incomplete descriptions... but guarantee that consumers will not understand when their location is collected and retained by Google or for what purposes\".\n",
        "\n",
        "It refers to dark patterns, design choices that alter users' decision-making for the designer's benefit - such as, complicated navigation menus, visual misdirection, confusing wording and repeated nudging towards a particular outcome.\n",
        "\n",
        "Data regulators are increasingly focusing on these practices.\n",
        "\n",
        "Google faces a raft of other legal actions in the US, including:\n",
        "\n",
        "In May 2020, Arizona filed a legal action over the same issue\n",
        "In December 2020, multiple US states sued over the price and process of advertising auctions\n",
        "In October 2020, the US Justice Department alleged Google had a monopoly over search and search advertising\"\"\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "kzD5yHCBTfKL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Brand Identification Class"
      ],
      "metadata": {
        "id": "rmq_-RXkbB1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BrandIdentification:\n",
        "    def __init__(self, MODEL_NAME):\n",
        "        self.MODEL_NAME = MODEL_NAME\n",
        "\n",
        "        # Define Spark NLP pipeline \n",
        "        documentAssembler = DocumentAssembler() \\\n",
        "            .setInputCol('text') \\\n",
        "            .setOutputCol('document')\n",
        "\n",
        "        tokenizer = Tokenizer() \\\n",
        "            .setInputCols(['document']) \\\n",
        "            .setOutputCol('token')\n",
        "\n",
        "        # ner_dl and onto_100 model are trained with glove_100d, so the embeddings in the pipeline should match\n",
        "        if (self.MODEL_NAME == \"ner_dl\") or (self.MODEL_NAME == \"onto_100\"):\n",
        "            embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\n",
        "                .setInputCols([\"document\", 'token']) \\\n",
        "                .setOutputCol(\"embeddings\")\n",
        "\n",
        "        # Bert model uses Bert embeddings\n",
        "        elif self.MODEL_NAME == \"ner_dl_bert\":\n",
        "            embeddings = BertEmbeddings.pretrained(name='bert_base_cased', lang='en') \\\n",
        "                .setInputCols(['document', 'token']) \\\n",
        "                .setOutputCol('embeddings')\n",
        "\n",
        "        ner_model = NerDLModel.pretrained(MODEL_NAME, 'en') \\\n",
        "            .setInputCols(['document', 'token', 'embeddings']) \\\n",
        "            .setOutputCol('ner')\n",
        "\n",
        "        ner_converter = NerConverter() \\\n",
        "            .setInputCols(['document', 'token', 'ner']) \\\n",
        "            .setOutputCol('ner_chunk')\n",
        "\n",
        "        nlp_pipeline = Pipeline(stages=[\n",
        "            documentAssembler, \n",
        "            tokenizer,\n",
        "            embeddings,\n",
        "            ner_model,\n",
        "            ner_converter\n",
        "        ])\n",
        "        \n",
        "        # Create the pipeline model\n",
        "        empty_df = spark.createDataFrame([['']]).toDF('text')\n",
        "        self.pipeline_model = nlp_pipeline.fit(empty_df)\n",
        "\n",
        "\n",
        "    def create_ranked_result_df(self, text):\n",
        "        # Run the pipeline for the text\n",
        "        text_df = spark.createDataFrame(pd.DataFrame({'text': text}, index = [0]))\n",
        "        result = self.pipeline_model.transform(text_df)\n",
        "        \n",
        "        # Tabulate results\n",
        "        df = result.select(F.explode(F.arrays_zip('document.result', 'ner_chunk.result',\"ner_chunk.metadata\")).alias(\"cols\")).select(\\\n",
        "        F.expr(\"cols['1']\").alias(\"chunk\"),\n",
        "        F.expr(\"cols['2'].entity\").alias('result'))\n",
        "        \n",
        "        # Rank the identified ORGs by frequencies\n",
        "        ranked_df = df.filter(df.result == 'ORG').groupBy(df.chunk).count().orderBy('count', ascending=False)\n",
        "\n",
        "        return ranked_df\n",
        "\n",
        "\n",
        "    def predict_by_headline(self, headline):\n",
        "        ranked_df_hl = self.create_ranked_result_df(headline)\n",
        "        ranked_df_hl.show(100, truncate=False)\n",
        "\n",
        "        # If only one ORG appears in headline, return it \n",
        "        if ranked_df_hl.count() == 1:\n",
        "            return ranked_df_hl.first()[0] \n",
        "        else: # If no ORG appears, or multiple ORGs all appear once, return no brand\n",
        "            return None\n",
        "\n",
        "\n",
        "    def predict(self, body):\n",
        "        ranked_df = self.create_ranked_result_df(body)\n",
        "        ranked_df.show(100, truncate=False)\n",
        "\n",
        "        # Return the ORG with highest freq (at least greater than 2)\n",
        "        if ranked_df.first()[1] > 2: \n",
        "            return ranked_df.first()[0] \n",
        "        else:\n",
        "            return None\n",
        "        # TO DO: break even - Wikidata#\n",
        "\n",
        "\n",
        "    # def visualise(self, ranked_df, result):\n",
        "        # Visualise ORG names in text\n",
        "        # NerVisualizer().display(\n",
        "            # result = result.collect()[0],\n",
        "            # label_col = 'ner_chunk',\n",
        "            # document_col = 'document',\n",
        "            # labels=['ORG']\n",
        "        #)\n"
      ],
      "metadata": {
        "id": "5JQeWnV1a8Fh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Senitment Identification Class"
      ],
      "metadata": {
        "id": "-5m65UosNdY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentIdentification:\n",
        "\n",
        "    def __init__(self, MODEL_NAME):\n",
        "        \"\"\"Creates a class for sentiment identication using specified model.\n",
        "\n",
        "        Args:\n",
        "          MODEL_NAME: Name of the Spark NLP pretrained pipeline.\n",
        "        \"\"\"\n",
        "\n",
        "        # Create the pipeline instance\n",
        "        self.MODEL_NAME = MODEL_NAME\n",
        "\n",
        "        if self.MODEL_NAME == \"custom_pipeline\": # https://nlp.johnsnowlabs.com/2021/11/03/bert_sequence_classifier_finbert_en.html\n",
        "          document_assembler = DocumentAssembler() \\\n",
        "              .setInputCol('text') \\\n",
        "              .setOutputCol('document')\n",
        "\n",
        "          tokenizer = Tokenizer() \\\n",
        "              .setInputCols(['document']) \\\n",
        "              .setOutputCol('token')\n",
        "\n",
        "          sequenceClassifier = BertForSequenceClassification \\\n",
        "                .pretrained('bert_sequence_classifier_finbert', 'en') \\\n",
        "                .setInputCols(['token', 'document']) \\\n",
        "                .setOutputCol('class') \\\n",
        "                .setCaseSensitive(True) \\\n",
        "                .setMaxSentenceLength(512)\n",
        "\n",
        "          pipeline = Pipeline(stages=[\n",
        "              document_assembler,\n",
        "              tokenizer,\n",
        "              sequenceClassifier\n",
        "          ])\n",
        "\n",
        "          self.pipeline_model = LightPipeline(pipeline.fit(spark.createDataFrame([['']]).toDF(\"text\")))\n",
        "\n",
        "        else:\n",
        "          self.pipeline_model = PretrainedPipeline(self.MODEL_NAME, lang = 'en')\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, text):\n",
        "        \"\"\"Predicts sentiment of the input string..\n",
        "\n",
        "        Args:\n",
        "          text: String to classify.\n",
        "        \"\"\"\n",
        "        self.text = text\n",
        "\n",
        "        # Annotate input text using pretrained model\n",
        "        annotations =  self.pipeline_model.annotate(self.text)\n",
        "\n",
        "        # Depending on the chosen pipeline the outputs will be slightly different\n",
        "        if self.MODEL_NAME == \"analyze_sentimentdl_glove_imdb\":\n",
        "          # print(f\"{annotations['sentiment']} {annotations['document']}\")\n",
        "\n",
        "          if isinstance(self.text, list):\n",
        "            return [annotation['sentiment'][0] for annotation in annotations] # Return the sentiment list of strings\n",
        "          else:\n",
        "            return annotations['sentiment'][0] # Return the sentiment string\n",
        "\n",
        "        else:\n",
        "          # print(f\"{annotations['class']} {annotations['document']}\")\n",
        "\n",
        "          if isinstance(self.text, list):\n",
        "            return [annotation['class'][0] for annotation in annotations] # Return the sentiment list of strings\n",
        "          else:\n",
        "            return annotations['class'][0] # Return the sentiment string"
      ],
      "metadata": {
        "id": "62AefsLpNiTB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify Brand in news article\n"
      ],
      "metadata": {
        "id": "MwBY37mRbKjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"ner_dl_bert\" # MODEL_NAME = \"onto_100\"\n",
        "\n",
        "brand_identifier = BrandIdentification(MODEL_NAME)\n",
        "headline, body = article\n",
        "\n",
        "headline_brand = brand_identifier.predict_by_headline(headline)\n",
        "print(headline)\n",
        "print(headline_brand)\n",
        "\n",
        "# Only use article body if no brand identified in the headline\n",
        "if headline_brand == None:\n",
        "    brand = brand_identifier.predict(body)\n",
        "    print(brand)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUgFEXqubJwk",
        "outputId": "78ac95a9-ce9b-4a00-cdab-926a8627e057"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.1 MB\n",
            "[OK!]\n",
            "ner_dl_bert download started this may take some time.\n",
            "Approximate size to download 15.4 MB\n",
            "[OK!]\n",
            "+------+-----+\n",
            "|chunk |count|\n",
            "+------+-----+\n",
            "|Google|1    |\n",
            "+------+-----+\n",
            "\n",
            "Google sued in US over 'deceptive' location tracking\n",
            "Google\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify article using chosen pipeline"
      ],
      "metadata": {
        "id": "HoTrh-sEUeRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identifier = SentimentIdentification(MODEL_NAME =  \"analyze_sentimentdl_glove_imdb\")\n",
        "# identifier = SentimentIdentification(MODEL_NAME =  \"classifierdl_bertwiki_finance_sentiment_pipeline\")\n",
        "identifier = SentimentIdentification(MODEL_NAME = \"custom_pipeline\") # Uses https://nlp.johnsnowlabs.com/2021/11/03/bert_sequence_classifier_finbert_en.html\n",
        "\n",
        "# Predict by headline\n",
        "headline = article[0]\n",
        "identifier.predict(headline)\n",
        "\n",
        "# Predict by body\n",
        "body = article[1]\n",
        "identifier.predict(body)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "RMwzvEYnPKEQ",
        "outputId": "cb88b1b6-bc12-4c87-c7a5-b41a9f35d348"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_sequence_classifier_finbert download started this may take some time.\n",
            "Approximate size to download 390.9 MB\n",
            "[OK!]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'negative'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the accuracy of sentiment using the Financial News Headline Dataset"
      ],
      "metadata": {
        "id": "5GVcdPcr3Ldk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data downloaded from here: https://www.kaggle.com/ankurzing/sentiment-analysis-for-financial-news/version/5\n",
        "# Upload data from local machine\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "metadata": {
        "id": "ICt2AFBB4VEG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alternatively download directly from kaggle using api keys"
      ],
      "metadata": {
        "id": "r20tUnSUyhbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/ankurzing/sentiment-analysis-for-financial-news?select=all-data.csv\")\n",
        "\n",
        "# Input the following username and key when prompted:\n",
        "# username: maxtimm\n",
        "# Key: e9e0955b8d40b7d939e21febfbea8d15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdW7RAb1ygtU",
        "outputId": "ca98d267-0667-4b81-d989-2f15152308ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.20-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.62.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (5.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2021.10.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.20\n",
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: maxtimm\n",
            "Your Kaggle Key: ··········\n",
            "Downloading sentiment-analysis-for-financial-news.zip to ./sentiment-analysis-for-financial-news\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 903k/903k [00:00<00:00, 88.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert Kaggle to dataframe and preprocess"
      ],
      "metadata": {
        "id": "LA3mYD2kK2V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import time\n",
        "\n",
        "# Store data in a Pandas Dataframe\n",
        "df_pandas = pd.read_csv(\"./sentiment-analysis-for-financial-news/all-data.csv\", encoding='latin-1')\n",
        "\n",
        "# Change column names (pipelines require a \"text\" column to predict)\n",
        "df_pandas.columns = ['True_Sentiment', 'text']\n",
        "\n",
        "# shuffle the DataFrame rows\n",
        "df_pandas = df_pandas.sample(frac = 1)\n",
        "\n",
        "# Make dataset smaller for faster runtime\n",
        "num_sentences = 500\n",
        "total_num_sentences = df_pandas.shape[0]\n",
        "df_pandas.drop(df_pandas.index[num_sentences:total_num_sentences], inplace=True)"
      ],
      "metadata": {
        "id": "nwLHDZohOPJQ"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify sentences one by one"
      ],
      "metadata": {
        "id": "0jQZPrKIOP3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the identifier object\n",
        "# identifier = SentimentIdentification(MODEL_NAME = \"custom_pipeline\") # 90.2% accuracy on 500 sentences 89.8% on 1000 sentences\n",
        "# identifier = SentimentIdentification(MODEL_NAME =  \"classifierdl_bertwiki_finance_sentiment_pipeline\") # Alternative pretrained pipeline 90.0% accuracy on 500 sentences\n",
        "\n",
        "preds = []\n",
        "target = []\n",
        "ignored_idxs = []\n",
        "sentiment_to_ignore = \"\" # e.g. neutral\n",
        "\n",
        "# Measure how long it takes\n",
        "start = time.time()\n",
        "\n",
        "# Collect predicted sentiment for each headline - take three minutes to run\n",
        "for idx, hl in enumerate(df_pandas['text']):\n",
        "\n",
        "    # Only append the sentiment if it is not the sentiment to ignore (e.g. neutral)\n",
        "    target_sentiment = df_pandas[\"True_Sentiment\"][df_pandas.index[idx]]\n",
        "\n",
        "    if target_sentiment != sentiment_to_ignore:\n",
        "      preds.append(identifier.predict(hl))\n",
        "    else:\n",
        "      ignored_idxs.append(idx)\n",
        "\n",
        "    # Print progress\n",
        "    if idx % 25 == 0:\n",
        "      print(f\"Classification {100*idx/num_sentences}% done.\")\n",
        "\n",
        "# Remove all ignored entries from dataset\n",
        "df_pandas.drop(df_pandas.index[ignored_idxs], inplace=True)\n",
        "\n",
        "df_pandas['Predicted_Sentiment'] = preds\n",
        "\n",
        "# Measure how long it takes\n",
        "end = time.time()\n",
        "print(f\"{end-start} seconds elapsed to classify {num_sentences} sentences.\")\n",
        "\n",
        "# Modify predicted labels to match with true labels\n",
        "# df = df.replace({'Predicted Sentiment': {'pos' : 'positive', 'neg' : 'negative'}})\n",
        "\n",
        "df_pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "5jFhoWw54zMo",
        "outputId": "0a398eb5-96c1-4dec-e35a-a248a7e6762d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification 0.0% done.\n",
            "Classification 25.0% done.\n",
            "Classification 50.0% done.\n",
            "Classification 75.0% done.\n",
            "22.427833795547485 seconds elapsed to classify 100 sentences.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ba23816e-22bb-4fa1-9eef-b1c26ef3fabc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>True_Sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>Predicted_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3836</th>\n",
              "      <td>neutral</td>\n",
              "      <td>The enterprise value of Maritim Food AS has be...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4054</th>\n",
              "      <td>negative</td>\n",
              "      <td>Finnish forest machinery manufacturer Ponsse h...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4413</th>\n",
              "      <td>negative</td>\n",
              "      <td>On top of that , the US Commerce Department pu...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3808</th>\n",
              "      <td>neutral</td>\n",
              "      <td>The composite body is coated with a hard coati...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4071</th>\n",
              "      <td>negative</td>\n",
              "      <td>Scanfil issued a profit warning on 10 April 20...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3792</th>\n",
              "      <td>neutral</td>\n",
              "      <td>The company expects its net sales for the whol...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2681</th>\n",
              "      <td>neutral</td>\n",
              "      <td>The site will cover over six hectares .</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3509</th>\n",
              "      <td>neutral</td>\n",
              "      <td>After the transaction , Danske Bank becomes an...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>724</th>\n",
              "      <td>positive</td>\n",
              "      <td>Okmetic 's products are based on high-tech exp...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3565</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Currently it operates a fleet of eight carrier...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba23816e-22bb-4fa1-9eef-b1c26ef3fabc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba23816e-22bb-4fa1-9eef-b1c26ef3fabc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba23816e-22bb-4fa1-9eef-b1c26ef3fabc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     True_Sentiment  ... Predicted_Sentiment\n",
              "3836        neutral  ...             neutral\n",
              "4054       negative  ...            negative\n",
              "4413       negative  ...            negative\n",
              "3808        neutral  ...             neutral\n",
              "4071       negative  ...            negative\n",
              "...             ...  ...                 ...\n",
              "3792        neutral  ...             neutral\n",
              "2681        neutral  ...             neutral\n",
              "3509        neutral  ...             neutral\n",
              "724        positive  ...            positive\n",
              "3565        neutral  ...             neutral\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Measure the Accuracy"
      ],
      "metadata": {
        "id": "OugF9Z-6t0PT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = df_pandas['True_Sentiment'].to_numpy()\n",
        "y_pred = df_pandas['Predicted_Sentiment'].to_numpy()\n",
        "\n",
        "print(f\"The accuracy is {100* sum(y_true==y_pred)/len(y_true)}%. \\n\")\n",
        "\n",
        "target_names = ['positive', 'neutral', 'negative']\n",
        "\n",
        "# Compute classification metrics - poor accuracy\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiLV0Glo_Kzj",
        "outputId": "d1624457-d59c-4e12-ce8b-79e20f66b734"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 92.0%. \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.94      0.94      0.94        16\n",
            "     neutral       0.89      0.96      0.93        53\n",
            "    negative       0.96      0.84      0.90        31\n",
            "\n",
            "    accuracy                           0.92       100\n",
            "   macro avg       0.93      0.91      0.92       100\n",
            "weighted avg       0.92      0.92      0.92       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classify using Spark Dataframe as input"
      ],
      "metadata": {
        "id": "PJc83LMsgJqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import array_join\n",
        "\n",
        "# Define pretrained pipeline\n",
        "pipeline = PretrainedPipeline(\"classifierdl_bertwiki_finance_sentiment_pipeline\", lang = 'en')\n",
        "\n",
        "# Convert to spark dataframe for faster prediction\n",
        "df_spark = spark.createDataFrame(df_pandas) \n",
        "\n",
        "# Measure how long it takes\n",
        "start = time.time()\n",
        "\n",
        "# Predict the sentiment\n",
        "df_spark = pipeline.transform(df_spark)\n",
        "\n",
        "# Extract only targets and labels\n",
        "df_spark = df_spark.select(\"text\", \"True_Sentiment\", \"class.result\")\n",
        "\n",
        "# Convert sentiment from a list to a string\n",
        "df_spark = df_spark.withColumn(\"Predicted_Sentiment\", array_join(\"result\", \"\"))\n",
        "\n",
        "# Convert to pandas dataframe for postprocessing (https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32)\n",
        "df_pandas = df_spark.toPandas()\n",
        "\n",
        "# df_pandas[\"Predicted_Sentiment\"] = df_pandas[\"Predicted_Sentiment\"].apply(lambda x: x[0]) # Alternative to convert list to string\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end-start} seconds elapsed to classify {num_sentences} sentences.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plG0dY_MZu5Z",
        "outputId": "f3b44e81-42c6-4ac2-9325-0fe9407a60d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifierdl_bertwiki_finance_sentiment_pipeline download started this may take some time.\n",
            "Approx size to download 412.9 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute the Accuracy"
      ],
      "metadata": {
        "id": "jsCyAYiYOutA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Compute the accuracy\n",
        "accuracy = accuracy_score(df_pandas[\"True_Sentiment\"], df_pandas[\"Predicted_Sentiment\"])\n",
        "print(f\"The accuracy is {accuracy*100}%.\")\n",
        "print(classification_report(df_pandas[\"True_Sentiment\"], df_pandas[\"Predicted_Sentiment\"]))\n",
        "\n",
        "# # Alternatively if not converted to pandas dataframe, use the following for the accuracy\n",
        "# # Compute accuracy by comparing each true label with predicted label\n",
        "# start = time.time()\n",
        "# accuracy = df_spark.filter(df_spark.Predicted_Sentiment == df_spark.True_Sentiment).count()/ num_sentences\n",
        "# end = time.time()\n",
        "# print(f\"{end-start} seconds elapsed to calculate accuracy of {num_sentences} sentences.\")\n",
        "# print(f\"The accuracy is {accuracy*100}%.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZsstjzhOtko",
        "outputId": "27816cf3-b47a-4b2a-df9e-eb8ab23ff845"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 88.0%.\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.93      0.87      0.90        15\n",
            "     neutral       0.90      0.90      0.90        63\n",
            "    positive       0.78      0.82      0.80        22\n",
            "\n",
            "    accuracy                           0.88       100\n",
            "   macro avg       0.87      0.86      0.87       100\n",
            "weighted avg       0.88      0.88      0.88       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alternatively extract predictions as strings (takes much longer)"
      ],
      "metadata": {
        "id": "bgCjIm4CK8mT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Extract the predictions from the dataframe\n",
        "# annotations_list = result.select(\"class.result\").collect()\n",
        "# sentiment_list = [annotations_list[i].result[0] for i in range(num_sentences)]\n",
        "\n",
        "# # Annotate previous dataframe for visualization\n",
        "# df_pandas['Predicted Sentiment'] = sentiment_list\n",
        "\n",
        "# # Move text column to the beginning\n",
        "# text_column = df_pandas.pop('text')\n",
        "# df_pandas.insert(0, 'Headline', text_column)\n",
        "\n",
        "# display(df_pandas)\n",
        "\n",
        "# y_true = df_pandas['True Sentiment'].to_numpy()\n",
        "# y_pred = df_pandas['Predicted Sentiment'].to_numpy()\n",
        "\n",
        "# print(f\"The accuracy is {100* sum(y_true==y_pred)/len(y_true)}%. \\n\")"
      ],
      "metadata": {
        "id": "FE7qhsf8LAre"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CLASS FOR SENTIMENT DETECTION USING SNOW LABS PIPELINES.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "45150093197569bb3a58481dcd32cd1adb45462fa3448719e8ac38ada6166aca"
    },
    "kernelspec": {
      "display_name": "Python 3.6.10 64-bit ('tensorflow2_p36': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}